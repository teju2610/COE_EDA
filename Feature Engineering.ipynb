{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "038b81d9",
   "metadata": {},
   "source": [
    "**What is Feature Engineering?**\n",
    " \n",
    "Feature engineering is the process of creating new features or modifying existing ones to improve the performance of machine learning models. It involves techniques like feature extraction, transformation, encoding, and scaling to make data more useful for predictions.\n",
    "\n",
    "**Why Do We Need Feature Engineering?**\n",
    "\n",
    "1.**Improves Model Performance** – Good features help models make better predictions.\n",
    " \n",
    "2.**Reduces Overfitting** – Helps eliminate noise and irrelevant data.\n",
    " \n",
    "3.**Handles Missing Data** – Creates meaningful replacements for missing values.\n",
    " \n",
    "4.**Enables Better Interpretability** – Makes features more understandable and useful.\n",
    "\n",
    "5.**Reduces Dimensionality** – Helps remove unnecessary data points, making the model efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02e6ebbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      TransactionDate  DayOfWeek  Hour  IsWeekend\n",
      "0 2025-02-05 14:30:00          2    14          0\n",
      "1 2025-02-06 18:45:00          3    18          0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'TransactionDate':pd.to_datetime(['2025-02-05 14:30:00','2025-02-06 18:45:00'])})\n",
    "df['DayOfWeek']=df['TransactionDate'].dt.dayofweek\n",
    "df['Hour']=df['TransactionDate'].dt.hour\n",
    "df['IsWeekend']=df['DayOfWeek'].apply(lambda x:1 if x>=5 else 0)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d78aea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UserID  AvgTransactionAmount\n",
      "0     101                 600.0\n",
      "1     102                 350.0\n",
      "2     103                1000.0\n"
     ]
    }
   ],
   "source": [
    "df_transactions=pd.DataFrame({\n",
    "    'UserID':[101,102,101,103,102],\n",
    "    'TransactionAmount':[500,300,700,1000,400]\n",
    "})\n",
    "df_user_avg=df_transactions.groupby('UserID')['TransactionAmount'].mean().reset_index()\n",
    "df_user_avg.rename(columns={'TransactionAmount':'AvgTransactionAmount'},inplace=True)\n",
    "print(df_user_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6efe6adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ProductCategory_Clothing  ProductCategory_Electronics  \\\n",
      "0                       0.0                          1.0   \n",
      "1                       1.0                          0.0   \n",
      "2                       1.0                          0.0   \n",
      "3                       0.0                          0.0   \n",
      "\n",
      "   ProductCategory_Grocery  \n",
      "0                      0.0  \n",
      "1                      0.0  \n",
      "2                      0.0  \n",
      "3                      1.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CVR\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "df=pd.DataFrame({'ProductCategory':['Electronics','Clothing','Clothing','Grocery']})\n",
    "encoder=OneHotEncoder(sparse=False)\n",
    "encoded_features=encoder.fit_transform(df[['ProductCategory']])\n",
    "df_encoded=pd.DataFrame(encoded_features,columns=encoder.get_feature_names_out())\n",
    "print(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce63a766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TransactionAmount  LogTransactionAmount\n",
      "0                100              4.615121\n",
      "1                200              5.303305\n",
      "2               5000              8.517393\n",
      "3              10000              9.210440\n",
      "4              20000              9.903538\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "df=pd.DataFrame({'TransactionAmount':[100,200,5000,10000,20000]})\n",
    "df['LogTransactionAmount']=np.log1p(df['TransactionAmount'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19818ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TransactionAmount  LogTransactionAmount  NormalizedTransactionAmount  \\\n",
      "0                100              4.615121                     0.000000   \n",
      "1                200              5.303305                     0.005025   \n",
      "2               5000              8.517393                     0.246231   \n",
      "3              10000              9.210440                     0.497487   \n",
      "4              20000              9.903538                     1.000000   \n",
      "\n",
      "   StandardizedTransactionAmount  \n",
      "0                      -0.937070  \n",
      "1                      -0.923606  \n",
      "2                      -0.277351  \n",
      "3                       0.395831  \n",
      "4                       1.742196  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "scaler=MinMaxScaler()\n",
    "df['NormalizedTransactionAmount']=scaler.fit_transform(df[['TransactionAmount']])\n",
    "standard_scaler=StandardScaler()\n",
    "df['StandardizedTransactionAmount']=standard_scaler.fit_transform(df[['TransactionAmount']])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a1d8d0",
   "metadata": {},
   "source": [
    "**Final Summary of Feature Engineering & Imbalanced Data Handling**\n",
    " \n",
    "Feature Extraction : Extract new insights from raw data (e.g., Hour, DayOfWeek)\n",
    " \n",
    "Aggregated Features : Calculate meaningful statistics (e.g., AvgTransactionAmountPerUser)\n",
    " \n",
    "Encoding : Convert categorical variables into numerical (One-Hot Encoding)\n",
    " \n",
    "Log Transformation : Reduce skewness in data distribution\n",
    " \n",
    "Feature Scaling : Normalize numerical features for better model performance\n",
    " \n",
    "Downsampling: Reduce the size of the majority class\n",
    " \n",
    "Upsampling : Increase the size of the minority class\n",
    " \n",
    "SMOTE(Synthetic Minority Over-sampling Technique) : Generate synthetic samples for the minority class"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
